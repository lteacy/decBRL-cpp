package dec_brl.proto;
import "Experiment.proto";

// Outcome of a single reinforcement learning timestep
message Outcome
{
   optional int32 episode = 1;   // episode number
   optional int32 timestep = 2;  // timestep number

   // A state/action variable id along with its value
   message Variable
   {
      required uint32 id = 1;    // unique id for this variable
      required uint32 value = 2; // index of observed value
   }

   // Observed factored reward
   message Reward
   {
      required uint32 id = 1;    // unique id for reward factor
      required float  value = 2; // observed value
   }

   repeated Variable state  = 3; // state values when actions where performed
   repeated Variable action = 4; // performed actions
   repeated Reward   reward = 5; // observed factored rewards

   // Number of milliseconds for learner to update policy after observing outcome
   optional uint32 UpdateTimeInMs = 6;

   // Number of milliseconds for learn to decide which actions to take
   optional uint32 ActTimeInMs = 7;

   // The following field ids are reserved for third party extensions
   extensions 100 to 199;
}

// Wrapper for storing messages to file.
message ResultMsg
{
   enum Type
   {
      OUTCOME = 1;
      SETUP = 2;
      END_MSG = 100;
   }

   // identifies which type of message this is
   required Type type = 1;

   // one of the following will be filled in
   optional Outcome outcome = 2;
   optional ExperimentSetup setup = 3;
}
